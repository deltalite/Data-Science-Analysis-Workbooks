{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the Titanic project, the Digit Recognizer Competition on Kaggle is meant for learning about computer vision. I've noticed that many of the submissions for this project use CNN. Due to SuperDataScience on Udemy, I am familiar with some common and useful machine learning models however at the start of this project, I know very little about Neural Networks and Deep Learning. My hope for this project is to gain some knowledge into how to and why you should set up Neural Networks in a certain way to create a model. \n",
    "Through this second project of mine, I hope to learn and clarify information on neural networks and use some new tools like keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train Summary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    42000.000000\n",
       "mean         4.456643\n",
       "std          2.887730\n",
       "min          0.000000\n",
       "25%          2.000000\n",
       "50%          4.000000\n",
       "75%          7.000000\n",
       "max          9.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "%matplotlib inline\n",
    "# Determine which keras tools you want to use\n",
    "\n",
    "# Load data\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "x_train = df_train.iloc[:,1:]\n",
    "y_train = df_train['label']\n",
    "\n",
    "# Verify data is valid (should be, coming from Kaggle)\n",
    "plt.hist(y_train, rwidth = 0.9)\n",
    "plt.title(\"Traing Set Digit Distribution\")\n",
    "plt.show()\n",
    "print(\"y_train Summary\")\n",
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pixel0   pixel1   pixel2   pixel3   pixel4   pixel5   pixel6   pixel7  \\\n",
       "count  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel8   pixel9  ...      pixel774      pixel775      pixel776  \\\n",
       "count  42000.0  42000.0  ...  42000.000000  42000.000000  42000.000000   \n",
       "mean       0.0      0.0  ...      0.219286      0.117095      0.059024   \n",
       "std        0.0      0.0  ...      6.312890      4.633819      3.274488   \n",
       "min        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "25%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "50%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "75%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "max        0.0      0.0  ...    254.000000    254.000000    253.000000   \n",
       "\n",
       "          pixel777      pixel778      pixel779  pixel780  pixel781  pixel782  \\\n",
       "count  42000.00000  42000.000000  42000.000000   42000.0   42000.0   42000.0   \n",
       "mean       0.02019      0.017238      0.002857       0.0       0.0       0.0   \n",
       "std        1.75987      1.894498      0.414264       0.0       0.0       0.0   \n",
       "min        0.00000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "25%        0.00000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "50%        0.00000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "75%        0.00000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "max      253.00000    254.000000     62.000000       0.0       0.0       0.0   \n",
       "\n",
       "       pixel783  \n",
       "count   42000.0  \n",
       "mean        0.0  \n",
       "std         0.0  \n",
       "min         0.0  \n",
       "25%         0.0  \n",
       "50%         0.0  \n",
       "75%         0.0  \n",
       "max         0.0  \n",
       "\n",
       "[8 rows x 784 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine how data looks\n",
    "x_train_array = x_train.to_numpy().flatten()\n",
    "plt.hist(x_train_array, rwidth = 0.9, bins=100)\n",
    "plt.title(\"Traing Set Input Distribution\")\n",
    "plt.show()\n",
    "print(\"x_train Summary\")\n",
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the input has a lot of zero values, where 0 indicates the abscence of writing in a visual representation of drawing these digits. With help from Yassine Ghouzam's Kaggle kernel (https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6), let's visualize what some of these inputs actually look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize input\n",
    "\n",
    "# calling it X_train since each set of imput will be an input matrix (denoted X) as oppose to the vector of inputs x\n",
    "# .reshape(-1) has the same effect as .flatten() seen above - I didn't specify reshape(num_cols, -1) so the default in a sense\n",
    "# is to flatten the np.array. It then reshapes it into 28x28x1 matrices, one for each picture input\n",
    "X_train = x_train.to_numpy().reshape(-1,28,28,1)\n",
    "# Try running this with (-1,28,28) and you'll notice\n",
    "# you get a 1xNumber_of_input_picturesx28x28 which is not as easy a format to deal with\n",
    "\n",
    "# Encode labels (digit value) to sparse vectors\n",
    "# ex. let n represent the label value\n",
    "#     vector_n = [(1 if digit == n else 0) for digit in label_options]\n",
    "#     5 => [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "y_train = to_categorical(y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cf970e2278>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly show one of the 42000 images in X_train\n",
    "plt.imshow(X_train[np.random.randint(42000)][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll be constructing my Convolutional Neural Network using Keras.\n",
    "\n",
    "After reading through a number of articles, it seems that there is no true proven, systematic way you should go about creating your CNN. That said, there are some standard ways to create CNNs for image recognition. There are also some conventions such as choosing a power of 2 for the number of convolution filters. Through looking at these commonly successful approaches, using intuition and some guessing, a good model can be developed. \n",
    "\n",
    "Of course, as we'll see later, there are some simple things such as increasing the number of epochs to increase the accuracy of your model. With data generation based off of the given data, each epoch trains the model (through backpropagation) with data altered from our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import deep learning objects\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Keras, you have the option to construct your ANN with a Sequential model or a Functional model.\n",
    "\n",
    "$\\underline{\\text{Sequential Model}}$\n",
    "\n",
    "A Sequential model makes it easy to create a straightforward deep learning model. Layers are added to the Sequential object and layers pass their outputs to the next layer in the sequence. This means with a few lines of code, you can build a pretty robust model, depending on the complexity of the problem at hand. This works for the digit recognizer since the layers have an order they should go in:\n",
    "\n",
    "Convolutional Filteration $\\rightarrow$ MaxPooling (Repeat previous two layers as needed) $\\rightarrow$ Flatten $\\rightarrow$ Dense Layer(s) $\\rightarrow$ Categorical Output\n",
    "\n",
    "$\\underline{\\text{Functional Model}}$\n",
    "\n",
    "A Functional model is highly customizable which allows for personalization such as having any layer communicate with any other layer. This is great for designing RNNs and other models that don't process data in the single, sequential way seen here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dex78\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dex78\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dex78\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dex78\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dex78\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dex78\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,\n",
    "                 kernel_size=3,\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Conv2D(64,\n",
    "                 kernel_size=3,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "# output_dim should be somewhere between the number of inputs and the number of outputs\n",
    "# again, following the power of 2 convension\n",
    "model.add(Dense(activation='relu', units=128))\n",
    "# softmax to output the classification with the highest probability\n",
    "# each element of y_train/the output is a digit (0-9)\n",
    "model.add(Dense(activation='softmax', units=10))\n",
    "# adam is a generally practical optimizer, \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create data generators\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2)\n",
    "\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dex78\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\dex78\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/25\n",
      "42/42 [==============================] - 31s 742ms/step - loss: 1.6721 - acc: 0.4377\n",
      "Epoch 2/25\n",
      "42/42 [==============================] - 31s 729ms/step - loss: 0.7649 - acc: 0.7630\n",
      "Epoch 3/25\n",
      "42/42 [==============================] - 30s 726ms/step - loss: 0.5272 - acc: 0.8409\n",
      "Epoch 4/25\n",
      "42/42 [==============================] - 31s 736ms/step - loss: 0.4229 - acc: 0.8719\n",
      "Epoch 5/25\n",
      "42/42 [==============================] - 31s 729ms/step - loss: 0.3703 - acc: 0.8885\n",
      "Epoch 6/25\n",
      "42/42 [==============================] - 30s 725ms/step - loss: 0.3348 - acc: 0.8979\n",
      "Epoch 7/25\n",
      "42/42 [==============================] - 31s 727ms/step - loss: 0.3033 - acc: 0.9080\n",
      "Epoch 8/25\n",
      "42/42 [==============================] - 31s 731ms/step - loss: 0.2781 - acc: 0.9148\n",
      "Epoch 9/25\n",
      "42/42 [==============================] - 31s 731ms/step - loss: 0.2679 - acc: 0.9187\n",
      "Epoch 10/25\n",
      "42/42 [==============================] - 31s 728ms/step - loss: 0.2428 - acc: 0.9260\n",
      "Epoch 11/25\n",
      "42/42 [==============================] - 31s 730ms/step - loss: 0.2396 - acc: 0.9262\n",
      "Epoch 12/25\n",
      "42/42 [==============================] - 31s 728ms/step - loss: 0.2264 - acc: 0.9319\n",
      "Epoch 13/25\n",
      "42/42 [==============================] - 31s 736ms/step - loss: 0.2157 - acc: 0.9349\n",
      "Epoch 14/25\n",
      "42/42 [==============================] - 31s 731ms/step - loss: 0.2002 - acc: 0.9395\n",
      "Epoch 15/25\n",
      "42/42 [==============================] - 31s 733ms/step - loss: 0.1937 - acc: 0.9402\n",
      "Epoch 16/25\n",
      "42/42 [==============================] - 31s 728ms/step - loss: 0.1866 - acc: 0.9429\n",
      "Epoch 17/25\n",
      "42/42 [==============================] - 31s 728ms/step - loss: 0.1824 - acc: 0.9452\n",
      "Epoch 18/25\n",
      "42/42 [==============================] - 31s 730ms/step - loss: 0.1787 - acc: 0.9460\n",
      "Epoch 19/25\n",
      "42/42 [==============================] - 30s 722ms/step - loss: 0.1741 - acc: 0.9458\n",
      "Epoch 20/25\n",
      "42/42 [==============================] - 31s 743ms/step - loss: 0.1657 - acc: 0.9492\n",
      "Epoch 21/25\n",
      "42/42 [==============================] - 31s 734ms/step - loss: 0.1622 - acc: 0.9498\n",
      "Epoch 22/25\n",
      "42/42 [==============================] - 31s 747ms/step - loss: 0.1581 - acc: 0.9514\n",
      "Epoch 23/25\n",
      "42/42 [==============================] - 32s 757ms/step - loss: 0.1481 - acc: 0.9545\n",
      "Epoch 24/25\n",
      "42/42 [==============================] - 31s 745ms/step - loss: 0.1504 - acc: 0.9533\n",
      "Epoch 25/25\n",
      "42/42 [==============================] - 31s 730ms/step - loss: 0.1434 - acc: 0.9564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf971eab38>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "# train model\n",
    "# fits model using the modification parameters entered above \n",
    "# with a batch_size of 1000, there will be 42 batches (42000 sample in X_train)\n",
    "model.fit_generator(train_data_gen.flow(X_train, y_train, batch_size=1000), epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Batches Explained}}$\n",
    "\n",
    "Batches are how many samples are fitted at a time - the models' dense layers' weights are updated after each batch.\n",
    "Large batches lead to fairly stable convergence of the model's weights. However, they take up more memory and take longer to train than smaller batches. So, some consideration has to be given to the machine you train your model on, as well as the size of your dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model\n",
    "import pickle\n",
    "filename = 'model.pickle' \n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in model\n",
    "with open(filename, 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse vector -> label\n",
    "# examine errors/confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission & Conclusion\n",
    "sample_sub = pd.read_csv('sample_submission.csv')\n",
    "sample_sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
